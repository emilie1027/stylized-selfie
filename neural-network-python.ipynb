{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from stylize import stylize\n",
    "import math\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "import vgg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sys import stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default arguments\n",
    "CONTENT_WEIGHT = 5e0\n",
    "STYLE_WEIGHT = 1e2\n",
    "TV_WEIGHT = 1e2\n",
    "LEARNING_RATE = 1e1\n",
    "STYLE_SCALE = 1.0\n",
    "ITERATIONS = 1000\n",
    "VGG_PATH = 'imagenet-vgg-verydeep-19.mat'\n",
    "\n",
    "CONTENT_LAYER = 'relu4_2'\n",
    "STYLE_LAYERS = ('relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imread(path):\n",
    "    return scipy.misc.imread(path).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Args(dict):\n",
    "    pass\n",
    "\n",
    "options = Args()\n",
    "options.content = 'examples/2-content.jpg'\n",
    "options.styles = ['examples/2-style1.jpg']\n",
    "options.output = 'examples/myoutput.jpg'\n",
    "options.iterations = 1\n",
    "options.network = VGG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'examples/2-content.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_image = imread(options.content)\n",
    "style_images = [imread(style) for style in options.styles]\n",
    "target_shape = content_image.shape\n",
    "for i in range(len(style_images)):\n",
    "    style_scale = STYLE_SCALE\n",
    "    #resize style image according to width faction\n",
    "    style_images[i] = scipy.misc.imresize(style_images[i], style_scale *\n",
    "            target_shape[1] / style_images[i].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = content_image\n",
    "styles = style_images\n",
    "iterations = options.iterations\n",
    "network = options.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize shape and features\n",
    "shape = (1,) + content.shape\n",
    "style_shapes = [(1,) + style.shape for style in styles]\n",
    "content_features = {}\n",
    "style_features = [{} for _ in styles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "# compute content features in feedforward mode\n",
    "with g.as_default(), g.device('/cpu:0'), tf.Session() as sess:\n",
    "    image = tf.placeholder('float', shape=shape)\n",
    "    net, mean_pixel = vgg.net(network, image)\n",
    "    content_pre = np.array([vgg.preprocess(content, mean_pixel)])\n",
    "    content_features[CONTENT_LAYER] = net[CONTENT_LAYER].eval(\n",
    "            feed_dict={image: content_pre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute style features in feedforward mode\n",
    "for i in range(len(styles)):\n",
    "    g = tf.Graph()\n",
    "    with g.as_default(), g.device('/cpu:0'), tf.Session() as sess:\n",
    "        image = tf.placeholder('float', shape=style_shapes[i])\n",
    "        net, _ = vgg.net(network, image)\n",
    "        style_pre = np.array([vgg.preprocess(styles[i], mean_pixel)])\n",
    "        for layer in STYLE_LAYERS:\n",
    "            features = net[layer].eval(feed_dict={image: style_pre})\n",
    "            features = np.reshape(features, (-1, features.shape[3]))\n",
    "            gram = np.matmul(features.T, features) / features.size\n",
    "            style_features[i][layer] = gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"features.png\">\n",
    "To create a graph with certain content and style, we want to first acquire the features of these contents and styles as a standard. Which means, we want our image to have both features included in content image and features in style images. Unsurprisingly, neurons in neural network are a great way to show these features according to its intuition. Thus, we utilize the pre-trained vgg network, input content image and style images and compute output of each layer in the network. Then, we choose some of the layers as features of the content and style.\n",
    "\n",
    "After having those features in hand, how can we create the stylized image? If we have an image that has has all the features in content and style images, then this image is exatly what we want. So let's first solve this problem - given an image, how can we measure the difference between this image and ideal image that has all the features? One thing we could do is to input our image into the neural network, compute output in each layer, pick certain layer as its features and compare its feature with corresponding content and style feature. The comparison could achieved using the loss function. \n",
    "\n",
    "As we form the loss function, our goal becomes to find an image that minimizes this loss function. This goal can be easily achieved using the backpropagation method using in neural network training process - We input a white noise image and use gradient descent to gradually change each pixel in the image to minimize the loss function.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
